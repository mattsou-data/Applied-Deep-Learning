{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jF_ENh3atCvf"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1171,
     "status": "ok",
     "timestamp": 1732619808176,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "I3JYDedSB02s"
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "# from google.colab import files, drive   # only needed if we run the code in google colab\n",
    "import getpass\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svxnefn2B5Yt"
   },
   "source": [
    "## User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3785,
     "status": "ok",
     "timestamp": 1732624385339,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "shzPziGAsy_l",
    "outputId": "a2cad570-19f9-4dd7-b677-02304b05a278"
   },
   "outputs": [],
   "source": [
    "# Create for yourself a youtube API key and paste it in the bar after launching this code \n",
    "\n",
    "api_key = getpass.getpass('Please enter your YouTube API key: ')\n",
    "\n",
    "# Playlist containing all the videos\n",
    "playlist_ids = ['PLKRyT68ziy5FMq-gYqsIpri_ln_k3a6ho']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1732624388995,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "hK5fMz-Zgg_F"
   },
   "outputs": [],
   "source": [
    "# Build the YouTube client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGeNx0lTCUNL"
   },
   "source": [
    "## Get Video IDs for Playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "error",
     "timestamp": 1732624396053,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "zL7LFvM4BO_a",
    "outputId": "60e595af-4813-49b3-ece3-7e17a617f7df"
   },
   "outputs": [],
   "source": [
    "# Takes around 9 seconds to run \n",
    "\n",
    "def get_all_video_ids_from_playlists(youtube, playlist_ids):\n",
    "    all_videos = []  # Initialize a single list to hold all video IDs\n",
    "\n",
    "    for playlist_id in playlist_ids:\n",
    "        next_page_token = None\n",
    "\n",
    "        # Fetch videos from the current playlist\n",
    "        while True:\n",
    "            playlist_request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token)\n",
    "            playlist_response = playlist_request.execute()\n",
    "\n",
    "            all_videos += [item['contentDetails']['videoId'] for item in playlist_response['items']]\n",
    "\n",
    "            next_page_token = playlist_response.get('nextPageToken')\n",
    "\n",
    "            if next_page_token is None:\n",
    "                break\n",
    "\n",
    "    return all_videos\n",
    "\n",
    "# Fetch all video IDs from the specified playlists\n",
    "video_ids = get_all_video_ids_from_playlists(youtube, playlist_ids)\n",
    "\n",
    "# Error with video id 254 (at row 255 in video_ids.csv) it is a private video\n",
    "del video_ids[254]\n",
    "\n",
    "# Save the list to a CSV file (to avoid using your API credit)\n",
    "with open('video_ids.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for item in video_ids:\n",
    "        writer.writerow([item])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ-LTgQatXIi"
   },
   "source": [
    "## Get All Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "error",
     "timestamp": 1732624410899,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "vUdZCrxHmnL8",
    "outputId": "113a46ba-a293-4fb3-8beb-153f4711275f"
   },
   "outputs": [],
   "source": [
    "# Takes around 18 minutes to run \n",
    "\n",
    "# Function to get replies for a specific comment\n",
    "def get_replies(youtube, parent_id, video_id):  \n",
    "    replies = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        reply_request = youtube.comments().list(\n",
    "            part=\"snippet\",\n",
    "            parentId=parent_id,\n",
    "            textFormat=\"plainText\",\n",
    "            maxResults=100,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        reply_response = reply_request.execute()\n",
    "\n",
    "        for item in reply_response['items']:\n",
    "            comment = item['snippet']\n",
    "            replies.append({\n",
    "                'Timestamp': comment['publishedAt'],\n",
    "                'Username': comment['authorDisplayName'],\n",
    "                'VideoID': video_id,\n",
    "                'Comment': comment['textDisplay'],\n",
    "                'Date': comment['updatedAt'] if 'updatedAt' in comment else comment['publishedAt']\n",
    "            })\n",
    "\n",
    "        next_page_token = reply_response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return replies\n",
    "\n",
    "# Function to get all comments (including replies) for a single video\n",
    "def get_comments_for_video(youtube, video_id):\n",
    "    all_comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        comment_request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            pageToken=next_page_token,\n",
    "            textFormat=\"plainText\",\n",
    "            maxResults=100\n",
    "        )\n",
    "        comment_response = comment_request.execute()\n",
    "\n",
    "        for item in comment_response['items']:\n",
    "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "            all_comments.append({\n",
    "                'Timestamp': top_comment['publishedAt'],\n",
    "                'Username': top_comment['authorDisplayName'],\n",
    "                'VideoID': video_id,  # Directly using video_id from function parameter\n",
    "                'Comment': top_comment['textDisplay'],\n",
    "                'Date': top_comment['updatedAt'] if 'updatedAt' in top_comment else top_comment['publishedAt']\n",
    "            })\n",
    "\n",
    "            # Fetch replies if there are any\n",
    "            if item['snippet']['totalReplyCount'] > 0:\n",
    "                all_comments.extend(get_replies(youtube, item['snippet']['topLevelComment']['id'], video_id))\n",
    "\n",
    "        next_page_token = comment_response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return all_comments\n",
    "\n",
    "# List to hold all comments from all videos\n",
    "all_comments = []\n",
    "\n",
    "\n",
    "for video_id in video_ids:\n",
    "    video_comments = get_comments_for_video(youtube, video_id)\n",
    "    all_comments.extend(video_comments)\n",
    "\n",
    "# Create DataFrame\n",
    "comments_df = pd.DataFrame(all_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQeo2iTwDROo"
   },
   "source": [
    "### Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1732623831605,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "-phDM_447hTR",
    "outputId": "0f3f67cc-e342-4c6a-aed8-bb53d46e0c86"
   },
   "outputs": [],
   "source": [
    "# Export whole dataset as CSV File\n",
    "csv_file = 'comments_data/combined_data.csv'  \n",
    "comments_df.to_csv(csv_file, index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/analyticswithadam/Python/blob/main/Pull_all_Comments_and_Replies_for_YouTube_Playlists.ipynb",
     "timestamp": 1732624450736
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
